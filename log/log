18/09/13 18:08:05 INFO conf.SharedConf : train.error does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : validate.error does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : predict does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : train.loss does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : validate.loss does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : train does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : log.likelihood does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : ml.gbdt.max.node.num does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : inctrain does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel-default.xml does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel-site.xml does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel. does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.am. does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.worker. does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.ps. does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.task. does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.workergroup. does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.train.data.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.predict.data.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.input.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.predict.out.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.temp.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.client.type does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.save.model.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.log.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.load.model.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.jar does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.ml.conf does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.libjars does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : queue does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.app.config.file does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.cache.archives does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.cache.files does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.complete.cancel.delegation.tokens does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.submit.host does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.submit.host.address does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.submit.user.name does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.job.dir does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.app.user.resource.files does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.app.serilize.state.file does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.output.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.tmp.output.path.prefix does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.tmp.output.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : ANGEL does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.jobid does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : job.xml does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.cluster.local.dir does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.workergroup.actual.number does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.worker.env does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.worker.java.opts does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.workergroup.failed.tolerate does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.worker.max-attempts does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.task.actual.number does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.ps.backup.matrices does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.ps.max-attempts does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.ps.child.opts does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.matrixtransfer.max.requestnum does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.psagent. does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.ps.ip.list does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.psagent.java.opts does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.psagent.iplist does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.model.parse.name does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.parse.model.path does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : ml.connection.timeout does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : netty.server.io.threads does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : netty.io.mode does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : netty.client.io.threads does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : ml.rpc.timeout does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.app.type does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.pyangel.python does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.pyangel.pyfile does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.pyangel.pyfile.dependencies does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.plugin.service.enable does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.sharding.num does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.sharding.concurrent.capacity does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.sharding.model.class does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.master.ip does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.master.port does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.model.name does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.model.load.timeout.minute does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.model.load.check.inteval.second does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.model.load.type does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : angel.serving.predict.local.output does not have default value!
18/09/13 18:08:05 INFO conf.SharedConf : [I@1990a65e does not have default value!
18/09/13 18:08:05 INFO spark.SparkContext : Running Spark version 2.1.0
18/09/13 18:08:05 WARN util.NativeCodeLoader : Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/09/13 18:08:05 INFO spark.SecurityManager : Changing view acls to: fitzwang
18/09/13 18:08:05 INFO spark.SecurityManager : Changing modify acls to: fitzwang
18/09/13 18:08:05 INFO spark.SecurityManager : Changing view acls groups to: 
18/09/13 18:08:05 INFO spark.SecurityManager : Changing modify acls groups to: 
18/09/13 18:08:05 INFO spark.SecurityManager : SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(fitzwang); groups with view permissions: Set(); users  with modify permissions: Set(fitzwang); groups with modify permissions: Set()
18/09/13 18:08:06 INFO util.Utils : Successfully started service 'sparkDriver' on port 60044.
18/09/13 18:08:06 INFO spark.SparkEnv : Registering MapOutputTracker
18/09/13 18:08:06 INFO spark.SparkEnv : Registering BlockManagerMaster
18/09/13 18:08:06 INFO storage.BlockManagerMasterEndpoint : Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/09/13 18:08:06 INFO storage.BlockManagerMasterEndpoint : BlockManagerMasterEndpoint up
18/09/13 18:08:06 INFO storage.DiskBlockManager : Created local directory at C:\Users\fitzwang\AppData\Local\Temp\blockmgr-4a1aa212-4fad-47e4-a56a-2bbb8681a5c1
18/09/13 18:08:06 INFO memory.MemoryStore : MemoryStore started with capacity 1990.8 MB
18/09/13 18:08:06 INFO spark.SparkEnv : Registering OutputCommitCoordinator
18/09/13 18:08:06 INFO util.log : Logging initialized @1686ms
18/09/13 18:08:06 INFO server.Server : jetty-9.2.z-SNAPSHOT
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5bc9ba1d{/jobs,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1021f6c9{/jobs/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@7516e4e5{/jobs/job,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@488eb7f2{/jobs/job/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5e81e5ac{/stages,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4189d70b{/stages/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3fa2213{/stages/stage,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3e7634b9{/stages/stage/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6f0b0a5e{/stages/pool,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@6035b93b{/stages/pool/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@320de594{/storage,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3dd1dc90{/storage/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@abf688e{/storage/rdd,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@478ee483{/storage/rdd/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@1a7288a3{/environment,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@2974f221{/environment/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@58fe0499{/executors,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@686449f9{/executors/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@665df3c6{/executors/threadDump,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@68b6f0d6{/executors/threadDump/json,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@4044fb95{/static,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@aa549e5{/,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@36f48b4{/api,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@5c00384f{/jobs/job/kill,null,AVAILABLE}
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@3b7ff809{/stages/stage/kill,null,AVAILABLE}
18/09/13 18:08:06 INFO server.ServerConnector : Started ServerConnector@b78a709{HTTP/1.1}{0.0.0.0:4040}
18/09/13 18:08:06 INFO server.Server : Started @1788ms
18/09/13 18:08:06 INFO util.Utils : Successfully started service 'SparkUI' on port 4040.
18/09/13 18:08:06 INFO ui.SparkUI : Bound SparkUI to 0.0.0.0, and started at http://10.13.64.62:4040
18/09/13 18:08:06 INFO executor.Executor : Starting executor ID driver on host localhost
18/09/13 18:08:06 INFO util.Utils : Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60057.
18/09/13 18:08:06 INFO netty.NettyBlockTransferService : Server created on 10.13.64.62:60057
18/09/13 18:08:06 INFO storage.BlockManager : Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/09/13 18:08:06 INFO storage.BlockManagerMaster : Registering BlockManager BlockManagerId(driver, 10.13.64.62, 60057, None)
18/09/13 18:08:06 INFO storage.BlockManagerMasterEndpoint : Registering block manager 10.13.64.62:60057 with 1990.8 MB RAM, BlockManagerId(driver, 10.13.64.62, 60057, None)
18/09/13 18:08:06 INFO storage.BlockManagerMaster : Registered BlockManager BlockManagerId(driver, 10.13.64.62, 60057, None)
18/09/13 18:08:06 INFO storage.BlockManager : Initialized BlockManager: BlockManagerId(driver, 10.13.64.62, 60057, None)
18/09/13 18:08:06 INFO handler.ContextHandler : Started o.s.j.s.ServletContextHandler@b93aad{/metrics/json,null,AVAILABLE}
18/09/13 18:08:06 INFO memory.MemoryStore : Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1990.7 MB)
18/09/13 18:08:06 INFO memory.MemoryStore : Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1990.7 MB)
18/09/13 18:08:06 INFO storage.BlockManagerInfo : Added broadcast_0_piece0 in memory on 10.13.64.62:60057 (size: 14.3 KB, free: 1990.8 MB)
18/09/13 18:08:06 INFO spark.SparkContext : Created broadcast 0 from textFile at LRTest.scala:68
18/09/13 18:08:07 INFO utils.UGITools : UGI_PROPERTY_NAME is null 
18/09/13 18:08:07 INFO client.AngelClient : running mode = ANGEL_PS
18/09/13 18:08:07 INFO utils.HdfsUtil : tmp output dir is file:///tmp/fitzwang/application_1536833287032_-752512586_d6cbffeb-db71-4f43-9e86-78c6e424b951
18/09/13 18:08:07 INFO utils.HdfsUtil : tmp output dir is file:///tmp/fitzwang/application_1536833287032_-752512586_a78ca5f5-203a-4331-9e24-efde6b7994c3
18/09/13 18:08:07 INFO client.AngelClient : angel.tmp.output.path=file:/tmp/fitzwang/application_1536833287032_-752512586_d6cbffeb-db71-4f43-9e86-78c6e424b951
18/09/13 18:08:07 INFO client.AngelClient : internal state file is file:/tmp/fitzwang/application_1536833287032_-752512586_a78ca5f5-203a-4331-9e24-efde6b7994c3/state
18/09/13 18:08:07 INFO localcluster.LocalCluster : start local cluster 88fb5db9-da3f-4919-82ef-8731b32ff803
18/09/13 18:08:07 INFO localcluster.LocalResourceManager : local rm handle a event LocalRMEvent [appId=application_1536833287032_-752512586, type=ALLOCATE]
18/09/13 18:08:07 INFO master.AngelApplicationMaster : app state output path = file:/tmp/fitzwang/application_1536833287032_-752512586_d6cbffeb-db71-4f43-9e86-78c6e424b951/app
18/09/13 18:08:07 INFO oplog.AppStateStorage : writeDir=file:/tmp/fitzwang/application_1536833287032_-752512586_d6cbffeb-db71-4f43-9e86-78c6e424b951/app
18/09/13 18:08:07 INFO master.AngelApplicationMaster : build app state storage success
18/09/13 18:08:07 INFO master.AngelApplicationMaster : build event dispacher
18/09/13 18:08:07 INFO master.AngelApplicationMaster : deploy mode=LOCAL
18/09/13 18:08:07 INFO event.AsyncDispatcher : Registering class com.tencent.angel.master.deploy.ContainerAllocatorEventType for class com.tencent.angel.master.deploy.local.LocalContainerAllocator
18/09/13 18:08:07 INFO master.AngelApplicationMaster : build containerAllocator success
18/09/13 18:08:07 INFO event.AsyncDispatcher : Registering class com.tencent.angel.master.deploy.ContainerLauncherEventType for class com.tencent.angel.master.deploy.local.LocalContainerLauncher
18/09/13 18:08:07 INFO master.AngelApplicationMaster : build containerLauncher success
18/09/13 18:08:07 INFO master.AngelApplicationMaster : build master service success
18/09/13 18:08:07 INFO master.AngelApplicationMaster : recoverPSAttemptIndex return is null
18/09/13 18:08:07 INFO event.AsyncDispatcher : Registering class com.tencent.angel.master.ps.ParameterServerManagerEventType for class com.tencent.angel.master.ps.ParameterServerManager
18/09/13 18:08:07 INFO event.AsyncDispatcher : Registering class com.tencent.angel.master.ps.ps.AMParameterServerEventType for class com.tencent.angel.master.AngelApplicationMaster$ParameterServerEventHandler
18/09/13 18:08:07 INFO event.AsyncDispatcher : Registering class com.tencent.angel.master.ps.attempt.PSAttemptEventType for class com.tencent.angel.master.AngelApplicationMaster$PSAttemptEventDispatcher
18/09/13 18:08:07 INFO master.AngelApplicationMaster : build PSManager success
18/09/13 18:08:07 INFO master.AngelApplicationMaster : running mode=ANGEL_PS
18/09/13 18:08:07 INFO event.AsyncDispatcher : Registering class com.tencent.angel.master.metrics.MetricsEventType for class com.tencent.angel.master.metrics.MetricsService
18/09/13 18:08:07 INFO event.AsyncDispatcher : Registering class com.tencent.angel.master.app.AppEventType for class com.tencent.angel.master.app.App
18/09/13 18:08:07 INFO event.AsyncDispatcher : Registering class com.tencent.angel.master.app.AppFinishEventType for class com.tencent.angel.master.AngelApplicationMaster$AppFinishEventHandler
18/09/13 18:08:07 INFO master.MasterService : listen ip:10.13.64.62, port:22563
18/09/13 18:08:07 INFO metrics.DistributeLog : algorithm log output directory=file:///tmp/spark-on-angel/685b18cf-90fd-4009-8d8a-bfc2faee2703
18/09/13 18:08:07 INFO slowcheck.SlowChecker : slowCheckEnable = false, checkIntervalMs = 60000
18/09/13 18:08:07 INFO ps.AMParameterServer : schedule ps server, psId: ParameterServer_0
18/09/13 18:08:07 INFO ps.AMParameterServer : scheduling PSAttempt_0_0
18/09/13 18:08:07 INFO ps.AMParameterServer : ParameterServer_0 AMParameterServer Transitioned from NEW to SCHEDULED
18/09/13 18:08:07 INFO attempt.PSAttempt : allocate ps server attempt resource, ps attempt id = PSAttempt_0_0
18/09/13 18:08:07 INFO attempt.PSAttempt : PSAttempt_0_0 PSAttempt Transitioned from NEW to SCHEDULED
18/09/13 18:08:07 INFO master.AngelApplicationMaster : appAttemptId.getAttemptId()=1
18/09/13 18:08:07 INFO attempt.PSAttempt : PSAttempt_0_0 PSAttempt Transitioned from SCHEDULED to ASSIGNED
18/09/13 18:08:07 INFO ps.ParameterServer : Initialize a parameter server
18/09/13 18:08:07 INFO ps.ParameterServerManager : PS PSAttempt_0_0 is registered in monitor!
18/09/13 18:08:07 INFO attempt.PSAttempt : has telled attempt started for attempid: PSAttempt_0_0
18/09/13 18:08:07 INFO attempt.PSAttempt : PSAttempt_0_0 PSAttempt Transitioned from ASSIGNED to RUNNING
18/09/13 18:08:07 INFO ps.AMParameterServer : ParameterServer_0 AMParameterServer Transitioned from SCHEDULED to RUNNING
18/09/13 18:08:07 INFO control.ParameterServerService : Starting parameter server service at 10.13.64.62:26636
18/09/13 18:08:07 INFO save.SnapshotDumper : Start snapshot dumper
18/09/13 18:08:07 INFO data.MatrixTransportServer : Use nio channel
18/09/13 18:08:07 INFO data.MatrixTransportServer : Server port = 26637
18/09/13 18:08:07 INFO master.MasterService : PSAttempt_0_0 is registered now!
18/09/13 18:08:07 INFO attempt.PSAttempt : PSAttempt_0_0 is registering, location: (10.13.64.62:26636)
18/09/13 18:08:07 INFO master.MasterService : PSAttempt_0_0 register finished!
18/09/13 18:08:07 INFO ps.ParameterServer : Register to AppMaster successfully
18/09/13 18:08:07 INFO ps.ParameterServer : Starting HeartbeatThread, interval is 200 ms
18/09/13 18:08:08 INFO local.AngelLocalClient : start to create rpc client to am
18/09/13 18:08:08 INFO local.AngelLocalClient : start ps success
18/09/13 18:08:08 INFO partitioner.RangePartitioner : start to split matrix MatrixContext{name='init', rowNum=1, colNum=1, validIndexNum=-1, maxRowNumInBlock=1, maxColNumInBlock=1, partitionerClass=class com.tencent.angel.ps.storage.partitioner.IntRangePartitioner, rowType=T_DOUBLE_DENSE, attributes={}, matrixId=0}
18/09/13 18:08:08 INFO partitioner.RangePartitioner : blockRow = 1, blockCol=1
18/09/13 18:08:08 INFO partitioner.RangePartitioner : partition count: 1
18/09/13 18:08:08 INFO master.MasterService : check matrix loaded request = matrixNames: "init"

18/09/13 18:08:08 INFO matrix.ServerMatrix : Creating a Server Matrix, id: 0, name: init
18/09/13 18:08:08 INFO storage.MatrixStorageManager : MatrixId [0] added.
18/09/13 18:08:08 WARN load.SnapshotRecover : ps: ParameterServer_0, attempt 0 failed without write snapshots!
18/09/13 18:08:08 INFO storage.MatrixStorageManager : start to load matrices :com.tencent.angel.model.PSMatricesLoadContext@c304ecf
18/09/13 18:08:09 INFO master.MasterService : check matrix loaded request = matrixNames: "init"

18/09/13 18:08:09 INFO master.MasterService : start to calculation
18/09/13 18:08:09 INFO app.App : application_1536833287032_-752512586Job Transitioned from NEW to INITED
18/09/13 18:08:09 INFO app.App : application_1536833287032_-752512586Job Transitioned from INITED to RUNNING
18/09/13 18:08:09 INFO master.MasterService : PSAgent register:psAgentId: 1
location {
  ip: "10.13.64.62"
  port: 24094
}

18/09/13 18:08:09 INFO psagent.PSAgent : PSAgent get matrices from master,1
18/09/13 18:08:09 INFO transport.MatrixTransportClient : Use nio channel
18/09/13 18:08:09 INFO transport.MatrixTransportClient : ByteOrder.nativeOrder()=LITTLE_ENDIAN
18/09/13 18:08:09 INFO mapred.FileInputFormat : Total input paths to process : 1
18/09/13 18:08:09 INFO spark.SparkContext : Starting job: count at OfflineLearner.scala:62
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Got job 0 (count at OfflineLearner.scala:62) with 1 output partitions
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Final stage: ResultStage 0 (count at OfflineLearner.scala:62)
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Parents of final stage: List()
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Missing parents: List()
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Submitting ResultStage 0 (MapPartitionsRDD[3] at randomSplit at OfflineLearner.scala:54), which has no missing parents
18/09/13 18:08:09 INFO memory.MemoryStore : Block broadcast_1 stored as values in memory (estimated size 3.9 KB, free 1990.7 MB)
18/09/13 18:08:09 INFO memory.MemoryStore : Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1990.7 MB)
18/09/13 18:08:09 INFO storage.BlockManagerInfo : Added broadcast_1_piece0 in memory on 10.13.64.62:60057 (size: 2.3 KB, free: 1990.8 MB)
18/09/13 18:08:09 INFO spark.SparkContext : Created broadcast 1 from broadcast at DAGScheduler.scala:996
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at randomSplit at OfflineLearner.scala:54)
18/09/13 18:08:09 INFO scheduler.TaskSchedulerImpl : Adding task set 0.0 with 1 tasks
18/09/13 18:08:09 INFO scheduler.TaskSetManager : Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 48042 bytes)
18/09/13 18:08:09 INFO executor.Executor : Running task 0.0 in stage 0.0 (TID 0)
18/09/13 18:08:09 INFO rdd.HadoopRDD : Input split: file:/E:/github/fitzwang/angel/data/a9a/a9a_123d_train.dummy:0+1424538
18/09/13 18:08:09 INFO Configuration.deprecation : mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/09/13 18:08:09 INFO Configuration.deprecation : mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/09/13 18:08:09 INFO Configuration.deprecation : mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/09/13 18:08:09 INFO Configuration.deprecation : mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/09/13 18:08:09 INFO Configuration.deprecation : mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/09/13 18:08:09 INFO memory.MemoryStore : Block rdd_2_0 stored as values in memory (estimated size 13.6 MB, free 1977.0 MB)
18/09/13 18:08:09 INFO storage.BlockManagerInfo : Added rdd_2_0 in memory on 10.13.64.62:60057 (size: 13.6 MB, free: 1977.2 MB)
18/09/13 18:08:09 INFO memory.MemoryStore : Block rdd_3_0 stored as values in memory (estimated size 13.6 MB, free 1963.4 MB)
18/09/13 18:08:09 INFO storage.BlockManagerInfo : Added rdd_3_0 in memory on 10.13.64.62:60057 (size: 13.6 MB, free: 1963.6 MB)
18/09/13 18:08:09 INFO executor.Executor : Finished task 0.0 in stage 0.0 (TID 0). 1965 bytes result sent to driver
18/09/13 18:08:09 INFO scheduler.TaskSetManager : Finished task 0.0 in stage 0.0 (TID 0) in 515 ms on localhost (executor driver) (1/1)
18/09/13 18:08:09 INFO scheduler.TaskSchedulerImpl : Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/09/13 18:08:09 INFO scheduler.DAGScheduler : ResultStage 0 (count at OfflineLearner.scala:62) finished in 0.555 s
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Job 0 finished: count at OfflineLearner.scala:62, took 0.635828 s
18/09/13 18:08:09 INFO spark.SparkContext : Starting job: count at OfflineLearner.scala:63
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Got job 1 (count at OfflineLearner.scala:63) with 1 output partitions
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Final stage: ResultStage 1 (count at OfflineLearner.scala:63)
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Parents of final stage: List()
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Missing parents: List()
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Submitting ResultStage 1 (MapPartitionsRDD[4] at randomSplit at OfflineLearner.scala:54), which has no missing parents
18/09/13 18:08:09 INFO memory.MemoryStore : Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 1963.4 MB)
18/09/13 18:08:09 INFO memory.MemoryStore : Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 1963.4 MB)
18/09/13 18:08:09 INFO storage.BlockManagerInfo : Added broadcast_2_piece0 in memory on 10.13.64.62:60057 (size: 2.3 KB, free: 1963.6 MB)
18/09/13 18:08:09 INFO spark.SparkContext : Created broadcast 2 from broadcast at DAGScheduler.scala:996
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at randomSplit at OfflineLearner.scala:54)
18/09/13 18:08:09 INFO scheduler.TaskSchedulerImpl : Adding task set 1.0 with 1 tasks
18/09/13 18:08:09 INFO scheduler.TaskSetManager : Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 48042 bytes)
18/09/13 18:08:09 INFO executor.Executor : Running task 0.0 in stage 1.0 (TID 1)
18/09/13 18:08:09 INFO storage.BlockManager : Found block rdd_2_0 locally
18/09/13 18:08:09 INFO memory.MemoryStore : Block rdd_4_0 stored as values in memory (estimated size 16.0 B, free 1963.4 MB)
18/09/13 18:08:09 INFO storage.BlockManagerInfo : Added rdd_4_0 in memory on 10.13.64.62:60057 (size: 16.0 B, free: 1963.6 MB)
18/09/13 18:08:09 INFO executor.Executor : Finished task 0.0 in stage 1.0 (TID 1). 1668 bytes result sent to driver
18/09/13 18:08:09 INFO scheduler.TaskSetManager : Finished task 0.0 in stage 1.0 (TID 1) in 20 ms on localhost (executor driver) (1/1)
18/09/13 18:08:09 INFO scheduler.TaskSchedulerImpl : Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/09/13 18:08:09 INFO scheduler.DAGScheduler : ResultStage 1 (count at OfflineLearner.scala:63) finished in 0.020 s
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Job 1 finished: count at OfflineLearner.scala:63, took 0.025629 s
18/09/13 18:08:09 INFO rdd.MapPartitionsRDD : Removing RDD 2 from persistence list
18/09/13 18:08:09 INFO storage.BlockManager : Removing RDD 2
18/09/13 18:08:09 INFO memory.MemoryStore : Block broadcast_3 stored as values in memory (estimated size 221.8 KB, free 1976.8 MB)
18/09/13 18:08:09 INFO memory.MemoryStore : Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.3 KB, free 1976.8 MB)
18/09/13 18:08:09 INFO storage.BlockManagerInfo : Added broadcast_3_piece0 in memory on 10.13.64.62:60057 (size: 5.3 KB, free: 1977.2 MB)
18/09/13 18:08:09 INFO spark.SparkContext : Created broadcast 3 from broadcast at OfflineLearner.scala:66
18/09/13 18:08:09 INFO spark.SparkContext : Starting job: reduce at OfflineLearner.scala:81
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Got job 2 (reduce at OfflineLearner.scala:81) with 1 output partitions
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Final stage: ResultStage 2 (reduce at OfflineLearner.scala:81)
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Parents of final stage: List()
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Missing parents: List()
18/09/13 18:08:09 INFO scheduler.DAGScheduler : Submitting ResultStage 2 (MapPartitionsRDD[6] at mapPartitions at OfflineLearner.scala:74), which has no missing parents
18/09/13 18:08:10 INFO memory.MemoryStore : Block broadcast_4 stored as values in memory (estimated size 5.6 KB, free 1976.8 MB)
18/09/13 18:08:10 INFO memory.MemoryStore : Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.1 KB, free 1976.8 MB)
18/09/13 18:08:10 INFO storage.BlockManagerInfo : Added broadcast_4_piece0 in memory on 10.13.64.62:60057 (size: 3.1 KB, free: 1977.2 MB)
18/09/13 18:08:10 INFO spark.SparkContext : Created broadcast 4 from broadcast at DAGScheduler.scala:996
18/09/13 18:08:10 INFO scheduler.DAGScheduler : Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at mapPartitions at OfflineLearner.scala:74)
18/09/13 18:08:10 INFO scheduler.TaskSchedulerImpl : Adding task set 2.0 with 1 tasks
18/09/13 18:08:10 INFO scheduler.TaskSetManager : Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 48233 bytes)
18/09/13 18:08:10 INFO executor.Executor : Running task 0.0 in stage 2.0 (TID 2)
18/09/13 18:08:10 INFO storage.BlockManager : Found block rdd_3_0 locally
18/09/13 18:08:10 WARN netlib.BLAS : Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/09/13 18:08:10 INFO jni.JniLoader : successfully loaded C:\Users\fitzwang\AppData\Local\Temp\jniloader2123488439778449762netlib-native_ref-win-x86_64.dll
18/09/13 18:08:10 ERROR executor.Executor : Exception in task 0.0 in stage 2.0 (TID 2)
java.lang.NullPointerException
	at com.tencent.angel.ml.core.network.layers.AngelGraph$$anonfun$feedData$1.apply(AngelGraph.scala:113)
	at com.tencent.angel.ml.core.network.layers.AngelGraph$$anonfun$feedData$1.apply(AngelGraph.scala:113)
	at com.tencent.angel.ml.core.network.layers.AngelGraph.com$tencent$angel$ml$core$network$layers$AngelGraph$$deepFirstDown(AngelGraph.scala:97)
	at com.tencent.angel.ml.core.network.layers.AngelGraph.feedData(AngelGraph.scala:112)
	at com.tencent.angel.spark.ml.core.GraphModel.forward(GraphModel.scala:62)
	at com.tencent.angel.spark.ml.core.OfflineLearner$$anonfun$train$1$$anonfun$2.apply(OfflineLearner.scala:77)
	at com.tencent.angel.spark.ml.core.OfflineLearner$$anonfun$train$1$$anonfun$2.apply(OfflineLearner.scala:74)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/13 18:08:10 WARN scheduler.TaskSetManager : Lost task 0.0 in stage 2.0 (TID 2, localhost, executor driver): java.lang.NullPointerException
	at com.tencent.angel.ml.core.network.layers.AngelGraph$$anonfun$feedData$1.apply(AngelGraph.scala:113)
	at com.tencent.angel.ml.core.network.layers.AngelGraph$$anonfun$feedData$1.apply(AngelGraph.scala:113)
	at com.tencent.angel.ml.core.network.layers.AngelGraph.com$tencent$angel$ml$core$network$layers$AngelGraph$$deepFirstDown(AngelGraph.scala:97)
	at com.tencent.angel.ml.core.network.layers.AngelGraph.feedData(AngelGraph.scala:112)
	at com.tencent.angel.spark.ml.core.GraphModel.forward(GraphModel.scala:62)
	at com.tencent.angel.spark.ml.core.OfflineLearner$$anonfun$train$1$$anonfun$2.apply(OfflineLearner.scala:77)
	at com.tencent.angel.spark.ml.core.OfflineLearner$$anonfun$train$1$$anonfun$2.apply(OfflineLearner.scala:74)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

18/09/13 18:08:10 ERROR scheduler.TaskSetManager : Task 0 in stage 2.0 failed 1 times; aborting job
18/09/13 18:08:10 INFO scheduler.TaskSchedulerImpl : Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/09/13 18:08:10 INFO scheduler.TaskSchedulerImpl : Cancelling stage 2
18/09/13 18:08:10 INFO scheduler.DAGScheduler : ResultStage 2 (reduce at OfflineLearner.scala:81) failed in 0.233 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 2, localhost, executor driver): java.lang.NullPointerException
	at com.tencent.angel.ml.core.network.layers.AngelGraph$$anonfun$feedData$1.apply(AngelGraph.scala:113)
	at com.tencent.angel.ml.core.network.layers.AngelGraph$$anonfun$feedData$1.apply(AngelGraph.scala:113)
	at com.tencent.angel.ml.core.network.layers.AngelGraph.com$tencent$angel$ml$core$network$layers$AngelGraph$$deepFirstDown(AngelGraph.scala:97)
	at com.tencent.angel.ml.core.network.layers.AngelGraph.feedData(AngelGraph.scala:112)
	at com.tencent.angel.spark.ml.core.GraphModel.forward(GraphModel.scala:62)
	at com.tencent.angel.spark.ml.core.OfflineLearner$$anonfun$train$1$$anonfun$2.apply(OfflineLearner.scala:77)
	at com.tencent.angel.spark.ml.core.OfflineLearner$$anonfun$train$1$$anonfun$2.apply(OfflineLearner.scala:74)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:796)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
18/09/13 18:08:10 INFO scheduler.DAGScheduler : Job 2 failed: reduce at OfflineLearner.scala:81, took 0.239734 s
